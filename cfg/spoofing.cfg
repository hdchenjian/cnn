[network]
batch=48
height=112
width=112
#width=96
channels=3
max_batches=10000

learning_rate=0.01
policy=poly
earning_rate_poly_power=4
#policy=steps
#steps=30,100,200
#scales=.1,.1,.1

momentum=0.9
decay=0.0005

#saturation = 1.02
#exposure = 1.05
#hue=.02

flip=1
#mean_value=127.5
#scale=0.0078125

classes = 2
accuracy_count_max=8000

[convolutional]
filters=64
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
filters=64
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
filters=64
size=3
stride=2
pad=1
weight_filler=xavier
activation=leaky

[route]
layers=-3

# Downsample 56

[convolutional]
filters=64
size=1
stride=2
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
filters=64
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
filters=64
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
filters=64
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
filters=64
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
weight_filler=xavier
activation=leaky

[route]
layers=-3

# Downsample 28
[convolutional]
batch_normalize=1
filters=128
size=1
stride=2
pad=0
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
weight_filler=xavier
activation=leaky

[route]
layers=-3

# Downsample 14
[convolutional]
batch_normalize=1
filters=256
size=1
stride=2
pad=0
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
weight_filler=xavier
activation=leaky

[route]
layers=-3

# Downsample 7
[convolutional]
batch_normalize=1
filters=512
size=1
stride=2
pad=0
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
weight_filler=xavier
activation=leaky

[shortcut]
from=-3

[dropout]
probability=.4

[connected]
output = 200
weight_filler=xavier
activation=linear

[connected]
output = 2
weight_filler=xavier
activation=linear

[softmax]
