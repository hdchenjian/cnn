[network]
batch=256
height=32
width=32
channels=3
max_batches=4000

learning_rate=0.01
policy=poly
learning_rate_poly_power=4
#policy=steps
#steps=30,100,200
#scales=.1,.1,.1

momentum=0.9
decay=0.0005

saturation = 1.05
exposure = 1.05
hue=.05

#flip=1
#mean_value=127.5
#scale=0.0078125

classes = 10

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
weight_filler=xavier
activation=prelu
lr_mult=1
lr_decay_mult=1
bias_mult=2
bias_decay_mult=0

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
weight_filler=gaussian
weight_filler_std=0.01
activation=prelu
lr_mult=1
lr_decay_mult=1
bias_mult=0
bias_decay_mult=0

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
weight_filler=gaussian
weight_filler_std=0.01
activation=prelu
lr_mult=1
lr_decay_mult=1
bias_mult=0
bias_decay_mult=0

[shortcut]
from=-3

# conv 2
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
weight_filler=xavier
activation=prelu
lr_mult=1
lr_decay_mult=1
bias_mult=2
bias_decay_mult=0

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=gaussian
weight_filler_std=0.01
activation=prelu
lr_mult=1
lr_decay_mult=1
bias_mult=0
bias_decay_mult=0

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=gaussian
weight_filler_std=0.01
activation=prelu
lr_mult=1
lr_decay_mult=1
bias_mult=0
bias_decay_mult=0

[shortcut]
from=-3

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=gaussian
weight_filler_std=0.01
activation=prelu
lr_mult=1
lr_decay_mult=1
bias_mult=0
bias_decay_mult=0

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
weight_filler=gaussian
weight_filler_std=0.01
activation=prelu
lr_mult=1
lr_decay_mult=1
bias_mult=0
bias_decay_mult=0

[shortcut]
from=-3

[connected]
lr_mult=1
lr_decay_mult=1
bias_mult=2
bias_decay_mult=0

output = 512
weight_filler=xavier
activation=linear

[normalize]
######################################################

[connected]
#output = 100
output = 10
lr_mult=1
lr_decay_mult=0
bias_mult=0
bias_decay_mult=0

weight_filler=xavier
weight_normalize=1
bias_term=0
activation=linear

[softmax]
label_specific_margin_bias=-0.35
margin_scale=30
